<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b8ed6fcbd4624f2e8fb2404a11fde710~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>


> [ShowMeAI](http://www.showmeai.tech/)**日报**系列全新升级！覆盖AI人工智能 工具&框架 | 项目&代码 | 博文&分享 | 数据&资源 | 研究&论文 等方向。点击查看 [**历史文章列表**](https://mp.weixin.qq.com/mp/homepage?__biz=Mzg2OTYyMTcwMw==&hid=2&sn=51f7bead52c41447cd0ecb3d57b884e7)，在公众号内订阅话题 **#ShowMeAI资讯日报**，可接收每日最新推送。点击 [**专题合辑&电子月刊**](http://www.showmeai.tech/tutorials/85) 快速浏览各专题全集。


## 🚗 全球大裁员 & AI大牛离职，Tesla 自动驾驶风雨飘摇啊

昨天特斯拉自动驾驶 Autopilot 负责人 Andrej Karpathy 宣布即将离职，与 Elon Musk 友好话别。叠加了全球大裁员、Twitter收购等话题的马斯克，再一次走进了我们的视线。

> ◉ 2022年6月初，马斯克给特斯拉员工们发了一封电子邮件，要求结束远程办公返回办公室，每周到岗40小时，否则就要离开公司。
>
> ◉ 转天，马斯克向内部高管发了一封『暂停全球所有招聘』的邮件，表示自己感觉经济将超级糟糕，要求削减特斯拉10%的员工。
>
> ◉ 随后，特斯拉中国取消了原定于6月16日、23日、30日举行的涉及销售、研发和供应链职位的招聘活动。此前，特斯拉中国在6月每个周四晚上7点都开启直播招聘。
>
> ◉ 6月底，特斯拉关停了位于加州圣马特奥的办公室，裁员200人，其中大部分都是数据标注员。

时间线来到7月， Andrej Karpathy 在推特上宣布自己将离职，并希望重拾自己长久以来对 AI 技术工作、开源和教育等方面的热情。这也引发了外界关于自动驾驶技术发展瓶颈的讨论。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/636c5c10e55c4141b3625fe9c59437fe~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

> Andrej Karpathy 就是大名鼎鼎 CS231n 课程的主要设计者和讲师。给大家推荐一份 [**深度学习与计算机视觉教程：斯坦福CS231n · 全套笔记解读**](http://www.showmeai.tech/tutorials/37)


# 工具&框架

## 🚧 『TLNewsSpider』舆情信息获取，狠心开源企业级舆情爬虫项目

[https://github.com/casual-silva/NewsCrawl](https://github.com/casual-silva/NewsCrawl)

TLNewsSpider 是一个舆情信息获取与可视化平台，基于 GNE（General News Extractor，通用新闻正文抽取）模块，抽取 300 多个舆情站点的正文内容、标题、作者、发布时间、图片地址和正文所在的标签源代码等信息。
项目主干技术覆盖python、scrapy、scrapyd、scrapydweb(开源管理平台)、mysql、redis，支持任意数量的爬虫一键运行、定时任务、批量删除、一键部署，并且可以实现爬虫监控可视化、配置集群爬虫分配策略、现成的docker一键部署等功能。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/54ec6fc967444ed2944762739887440c~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>


## 🚧 『Upgini』机器学习自动化数据特征搜索/扩充库

[https://github.com/upgini/upgini](https://github.com/upgini/upgini)

外部数据和特征可以显著提升监督学习模型的准确度，但是费时费力。本 repo 将这个过程自动化啦——在几分钟内提升模型效果，精准扩充有用的特征！Upgini 是一个简单的特征搜索和扩充库，可以在公共数据集或社区共享的数据源中，自动检索『开箱即用』的数千个特征，并筛选、返回能提高模型预测能力的相关特征。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/432c95eebf584ebfbf90bd4cce69304d~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

## 🚧 『PrimeQA』最先进的多语言问答（QA）开发库

[https://github.com/primeqa/primeqa](https://github.com/primeqa/primeqa)

PrimeQA 是基于Transformers 的开源库，可以训练最先进的回答（QA）模型。使用 PrimeQA ，研发人员既可以复现最新NLP会议论文，也可以在自定义数据中下载并运行预训练的模型。PrimeQA 支持『基于传统BM25的信息检索』『ColBERT神经网络信息检索』『基于XLM-R的机器阅读理解』『新闻&电影上的多媒体问答』，在信息检索与问答场景提供端到端解决方案。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5af8fe6dac6e41c99b913498341025bb~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

## 🚧 『Chinese-CLIP』CLIP模型的中文版

[https://github.com/OFA-Sys/Chinese-CLIP](https://github.com/OFA-Sys/Chinese-CLIP)

本 repo 为 CLIP 模型的中文版本，帮助用户实现中文领域的跨模态检索、图像表示等功能。项目使用大规模中文数据（约2亿图文对）进行训练，并且对『open_clip project』原始项目代码在中文数据上的效果进行了优化。项目作者在持续努力中，『开源 ViT-L-14 规模 Chinese-CLIP 模型』正在训练中，后续也将提供基于 Chinese-CLIP 的图文检索demo 及其用户在自己环境中的部署流程等等~ 良心制作，值得持续关注！

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e490066de85d4c519992fa4a66f2f045~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

## 🚧 『socks5lb』非常简单的 Socks5 Proxy 负载均衡

[https://github.com/mingcheng/socks5lb](https://github.com/mingcheng/socks5lb)

以科学的方式上网时，如果遇到 Socks5 Proxy 无法联通的情况，往往需要手工切换节点，不仅麻烦还会中断网络请求。为了解决这个问题，作者编写了 socks5lb 工具（针对Socks5 Proxy 前置负载均衡器），提供经过检验的、稳定可靠的 Socks Proxy 节点。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8b8c55c7dfbf483c9820b564134fe752~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>


# 博文&分享

## 📚 『NeRF at CVPR 2022』分享：CVPR 2022的NeRF相关成果汇总

[https://dellaert.github.io/NeRF22/](https://dellaert.github.io/NeRF22/)

本文作者 Frank Dellaert 是美国 Georgia Institute of Technology 的教授，同时也是谷歌AI研究科学家。他与曾经的学生、现在的 Google 同事 Andrew Marmon 一道，对 CVPR 2022 会议上与神经辐射场（NeRFs）相关的50多篇论文进行了整理汇总。NeRFs 领域的研究和论文正在井喷式增长！连作者这样的大佬都感叹『确实有点卷不动』了。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8f972d34c15447bd9d38bd69dcbb9994~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0c30a70caf9d44b39ad227b0e94c3ee8~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

# 数据&资源

## 🔥『神经网络语音分离』必读论文/教程列表，Speech Separation based on Neural Networks

[https://github.com/JusperLee/Speech-Separation-Paper-Tutorial](https://github.com/JusperLee/Speech-Separation-Paper-Tutorial)


<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b4630834fb2043eb989be735e3986c4d~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

# 研究&论文

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/96a96ef4d4074be6bacd4fd36da26811~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

> 公众号后台回复关键字 **日报**，免费获取整理好的论文合辑。


> **科研进展**
> 
> - 2022.07.07 『**计算机视觉**』 Towards a General Purpose CNN for Long Range Dependencies in $N$D
> - ICLR 2022 『**模型压缩**』 SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation
> - 2021.07.06 『**自然语言处理**』 The FLORES-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation
> - 2022.07.06 『**图机器学习**』 Pure Transformers are Powerful Graph Learners

## ⚡ 论文：Towards a General Purpose CNN for Long Range Dependencies in $N$D

**论文标题**：Towards a General Purpose CNN for Long Range Dependencies in $N$D

**论文时间**：7 Jun 2022

**所属领域**：**计算机视觉**

**论文地址**：https://arxiv.org/abs/2206.03398

**代码实现**：https://github.com/david-knigge/ccnn

**论文作者**：David W. Romero, David M. Knigge, Albert Gu, Erik J. Bekkers, Efstratios Gavves, Jakub M. Tomczak, Mark Hoogendoorn

**论文简介**：The use of Convolutional Neural Networks (CNNs) is widespread in Deep Learning due to a range of desirable model properties which result in an efficient and effective machine learning framework./卷积神经网络（CNN）的使用在深度学习中非常普遍，因为它具有一系列理想的模型属性，从而形成了一个高效和有效的机器学习框架。

> **论文摘要**：卷积神经网络（CNN）的使用在深度学习中非常普遍，因为它具有一系列理想的模型属性，从而形成了一个高效和有效的机器学习框架。然而，高性能的CNN架构必须为特定的任务量身定做，以纳入诸如输入长度、分辨率和尺寸等考虑因素。在这项工作中，我们用我们的连续卷积神经网络（CCNN）克服了对特定问题的CNN架构的需求：一个配备了连续卷积核的单一CNN架构，可用于任意分辨率、维度和长度的数据的任务，而无需改变结构。连续卷积核对每一层的长距离依赖性进行建模，并消除了当前CNN架构中所需要的降采样层和任务依赖深度。我们通过将相同的CCNN应用于连续（一维）和视觉数据（二维）的广泛任务，展示了我们方法的通用性。我们的CCN在所考虑的所有任务中都表现得很有竞争力，并经常超过目前最先进的水平。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e55031607c4440f3bcbd1479708a2e40~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/837f45ea7c504fda8676d0c45839a10e~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation

**论文标题**：SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation

**论文时间**：ICLR 2022

**所属领域**：**模型压缩**

**对应任务**：Data Free Quantization，Quantization，量化，网络量化

**论文地址**：https://arxiv.org/abs/2202.07471

**代码实现**：https://github.com/clevercool/SQuant

**论文作者**：Cong Guo, Yuxian Qiu, Jingwen Leng, Xiaotian Gao, Chen Zhang, Yunxin Liu, Fan Yang, Yuhao Zhu, Minyi Guo

**论文简介**：This paper proposes an on-the-fly DFQ framework with sub-second quantization time, called SQuant, which can quantize networks on inference-only devices with low computation and memory requirements./本文提出了一个具有亚秒级量化时间的即时DFQ框架，称为SQuant，它可以在仅有推理能力的设备上对网络进行量化，对计算和内存的要求很低。


> **论文摘要**：深度神经网络（DNN）的量化已被证明对压缩和加速DNN模型很有效。无数据量化（DFQ）是一种很有前途的方法，在隐私敏感和保密的情况下没有原始数据集。然而，目前的DFQ解决方案降低了准确性，需要合成数据来校准网络，而且费时费钱。本文提出了一个具有亚秒级量化时间的即时DFQ框架，称为SQuant，它可以在仅有推理的设备上对网络进行量化，对计算和内存的要求很低。通过对DNN任务损失的二阶信息的理论分析，我们将基于Hessian的优化目标分解并近似为三个对角线子项，这些子项有不同的区域，分别对应于权重张量的三个维度：元素维度、内核维度和输出通道维度。然后，我们逐步组成子项目，并在离散域中提出了一个新的无数据优化目标，即最小化受限绝对误差总和（简称CASE），令人惊讶的是，它不需要任何数据集，甚至不知道网络结构。我们还设计了一个没有反向传播的高效算法，以进一步降低目标求解器的计算复杂性。最后，在没有微调和合成数据集的情况下，SQuant将无数据量化过程加速到亚秒级，与现有的无数据训练后量化工作相比，准确率提高了30%以上，所评估的模型为4位量化。我们已将SQuant框架开源到https://github.com/clevercool/SQuant。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c00cf936595d4fc88b7168782661e16d~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8a1e63beb1994478a9b65df023c2bcba~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：The FLORES-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation

**论文标题**：The FLORES-101 Evaluation Benchmark for Low-Resource and Multilingual Machine Translation

**论文时间**：6 Jun 2021

**所属领域**：**自然语言处理**

**对应任务**：Machine Translation，Translation，机器翻译

**论文地址**：https://arxiv.org/abs/2106.03193

**代码实现**：https://github.com/facebookresearch/flores,https://github.com/ibraheem-moosa/xlm-indic

**论文作者**：Naman Goyal, Cynthia Gao, Vishrav Chaudhary, Peng-Jen Chen, Guillaume Wenzek, Da Ju, Sanjana Krishnan, Marc'Aurelio Ranzato, Francisco Guzman, Angela Fan

**论文简介**：One of the biggest challenges hindering progress in low-resource and multilingual machine translation is the lack of good evaluation benchmarks./阻碍低资源和多语言机器翻译进展的最大挑战之一是缺乏良好的评估基准。


> **论文摘要**：阻碍低资源和多语言机器翻译进展的最大挑战之一是缺乏良好的评估基准。目前的评估基准要么缺乏对低资源语言的良好覆盖，要么只考虑有限的领域，要么质量不高，因为它们是用半自动程序构建的。在这项工作中，我们介绍了FLORES-101评估基准，包括从英语维基百科中提取的3001个句子，涵盖各种不同的主题和领域。这些句子由专业翻译人员通过精心控制的过程翻译成101种语言。由此产生的数据集能够更好地评估低资源语言长尾的模型质量，包括评估多对多的多语言翻译系统，因为所有的翻译都是多语言对齐的。通过公开发布这样一个高质量和高覆盖率的数据集，我们希望能促进机器翻译界及其他领域的进步。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5015ce8202b14c8888982a8cfed7f602~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0444757bc2c1403bb3c15fb8f2d106ee~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/701393a5b10b4009ad605e92972136b0~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：Pure Transformers are Powerful Graph Learners

**论文标题**：Pure Transformers are Powerful Graph Learners

**论文时间**：6 Jul 2022

**所属领域**：**图机器学习**

**对应任务**：Graph Learning，Inductive Bias，图学习，归纳偏置

**论文地址**：https://arxiv.org/abs/2207.02505

**代码实现**：https://github.com/jw9730/tokengt

**论文作者**：Jinwoo Kim, Tien Dat Nguyen, Seonwoo Min, Sungjun Cho, Moontae Lee, Honglak Lee, Seunghoon Hong

**论文简介**：We show that standard Transformers without graph-specific modifications can lead to promising results in graph learning both in theory and practice./我们表明，在理论上和实践上，标准的Transformers不需要对图进行特定的修改，就能在图学习中取得可喜的成果。



> **论文摘要**：我们表明，标准的Transformers无需对图进行特定的修改，在理论上和实践上都能在图的学习中取得可喜的成果。给定一个图，我们简单地将所有的节点和边作为独立的标记，用标记嵌入来增强它们，并将它们送入Transformers。通过对标记嵌入的适当选择，我们证明这种方法在理论上至少与由等价线性层组成的不变图网络（2-IGN）一样具有表现力，而后者已经比所有消息传递图神经网络（GNN）更具有表现力。当在一个大规模的图数据集（PCQM4Mv2）上进行训练时，我们的方法（Tokenized Graph Transformer，TokenGT）与GNN基线相比，取得了明显更好的结果，与具有复杂的图特定归纳偏置的Transformer变体相比，也取得了有竞争力的结果。我们的实现可以在https://github.com/jw9730/tokengt。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/88a45e052425432abae69b26fe71dc1b~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>


> 我们是 [**ShowMeAI**](http://www.showmeai.tech/tutorials/85)，致力于传播AI优质内容，分享行业解决方案，用知识加速每一次技术成长！点击查看 [**历史文章列表**](https://mp.weixin.qq.com/mp/homepage?__biz=Mzg2OTYyMTcwMw==&hid=2&sn=51f7bead52c41447cd0ecb3d57b884e7)，在公众号内订阅话题 **#ShowMeAI资讯日报**，可接收每日最新推送。点击 [**专题合辑&电子月刊**](http://www.showmeai.tech/tutorials/85) 快速浏览各专题全集。


<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9ac4d9eaa5794434ac7a14055501e4c7~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>


- 作者：[韩信子](https://github.com/HanXinzi-AI)@[ShowMeAI](http://www.showmeai.tech/tutorials/85)
- [**历史文章列表**](https://mp.weixin.qq.com/mp/homepage?__biz=Mzg2OTYyMTcwMw==&hid=2&sn=51f7bead52c41447cd0ecb3d57b884e7)
- [**专题合辑&电子月刊**](http://www.showmeai.tech/tutorials/85) 
- **声明：版权所有，转载请联系平台与作者并注明出处**
- **欢迎回复，拜托点赞，留言推荐中有价值的文章、工具或建议，我们都会尽快回复哒~**