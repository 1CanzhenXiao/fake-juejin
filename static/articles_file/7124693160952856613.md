本文已参与「新人创作礼」活动，一起开启掘金创作之路。

朋友们，今天继续讲解语音识别，前面讲到了进入模型的初步操作，这个模型的层数是非常多的，后面还要经过非常多的层，可以说是一个deep+deep 网络，所以，咱们今天继续跟着网络层forward！


## 1、网络展示

```
(self_attn): RelPositionMultiHeadedAttention(
 (linear_q): Linear(in_features=512, out_features=512, dtype=float32)
 (linear_k): Linear(in_features=512, out_features=512, dtype=float32)
 (linear_v): Linear(in_features=512, out_features=512, dtype=float32)
 (linear_out): Linear(in_features=512, out_features=512, dtype=float32)
 (dropout): Dropout(p=0.0, axis=None, mode=upscale_in_train)
  (linear_pos): Linear(in_features=512, out_features=512, dtype=float32)
 )
```
如上，之前我讲到数据经过层Conv2dSubsampling4后，shape变成了（1，90，512），然后，这个维度的数据还得继续往下forward，接下来的层变成了上面的名字：RelPositionMultiHeadedAttention，这一层也就是多头注意力机制，下面咱们往下forward。

## 2、网络提取

网络展示的是上面的结构，但是构建这个结构是非常复杂的，需要一点点构建，本次构建attention就不详细讲了，后文中咱们再讲，本次还是从架构和总体层面forward。
````
import pickle
with open("cls.pkl", "rb") as tf:    
    cls = pickle.load(tf)
````
```
import pickle
with open("configs.pkl", "rb") as tf:
    configs = pickle.load(tf)
```
```
model0 = cls(configs)
model_attn=model0.sublayers()[0].sublayers()[11][0].sublayers()[0]
```

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9b1fee6819774328b14685fe8d6ecc29~tplv-k3u1fbpfcp-watermark.image?)

可以看到，之前我们加载的模型，通过层层去找，就可以找到我们现在需要forward的模型，那么，这个模型我需要把数据怼进去，下面咱们先用随机数据试试。

## 3、forwad

前面咱们经过了网络Conv2dSubsampling4，下面是输出的结果。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/638ea96b9dde4b5eb0462975a73c0332~tplv-k3u1fbpfcp-watermark.image?)

然后，模型要看怎么输入，下面是输入参数，很明显，需要query、key、value、pos-embed和mask参数，那咱们用x输入，然后随机初始化一些数值输入试试。

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d5fec6c489eb424d9deb4d6c33ef3cfe~tplv-k3u1fbpfcp-watermark.image?)

```
model_attn(x,x,x,x,paddle.randn([1,1,90]))
```

![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/241b66cb20144b408eafdc524dc0eba6~tplv-k3u1fbpfcp-watermark.image?)

好了，我们假设了一些数据，然后怼入网络层，实现了上面的效果，相当于又走了一层，但是这样很难看出细节，下面咱们通过pycharm进行debug再看看。

## 4、debug

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c557c18826ac4d6a9a44e4ab79df3ce5~tplv-k3u1fbpfcp-watermark.image?)

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2a773cf5606042368ceeff2319b338fa~tplv-k3u1fbpfcp-watermark.image?)

前面的代码可以看到，通过一个for循环挨个forward每一层的layer，咱们目前进入的是ConformerEncoderLayer，然后这里面包括很多，我们只要RelPositionMultiHeadedAttention这一个，下面继续走。

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/937024551dde4574be24659adf9b0e06~tplv-k3u1fbpfcp-watermark.image?)


这一层的输入参数可以看到，可以认为是三个x+pos-emb+mask，至于pos-emb之前文章讲过了，mask先不讲，咱们看后面的。

![image.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3ec484e281bc449988831c207fd781ba~tplv-k3u1fbpfcp-watermark.image?)

到了forward里面，又来了一个qkv，下面继续走。

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3fbe990f551b4bcfb3fcee939f6ba7c1~tplv-k3u1fbpfcp-watermark.image?)

这里就简单了，实际上是计算q、k和v三个值，函数是一样的，咱们只进入第一个看看。


![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fb0cdd884f904127b85125ec7d9134a4~tplv-k3u1fbpfcp-watermark.image?)

linear层，实际上就是一个矩阵计算，这部分就是一个算子，算子基本上都是cpp实现的，就不详细讲了，想了解的请看：
>https://code.ihub.org.cn/projects/680/repository/revisions/develop/entry/paddle/fluid/operators/matmul_v2_op.cc


![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/beaf0a0e48bc45778db3fff67ac050fb~tplv-k3u1fbpfcp-watermark.image?)

完成这一步，后面都是常规操作，计算scores，这个自己看。


![image.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/720a8f4e59114ab384dbf447d38bb553~tplv-k3u1fbpfcp-watermark.image?)

socres完成后，其实就是计算相关性了，如上代码，到了这里其实这一层的forward就完成了，后面其实还有concate等，就不讲了。