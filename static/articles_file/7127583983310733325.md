 我正在参加「创意开发 投稿大赛」详情请看：[掘金创意开发大赛来了！](https://juejin.cn/post/7120441631530549284) 

# 一、基于PaddleGAN精准唇形合成模型实现美女表白视频





## 1. PaddleGAN的唇形迁移能力--Wav2lip
**铛铛铛！！飞桨[PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN)这就来给大家揭秘，手把手教大家如何实现唇型的迁移，学习过本项目的你们，从此不仅能让苏轼念诗，还能让蒙娜丽莎播新闻、新闻主播唱Rap... 只有你想不到的，没有[PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN)做不到的！**

本教程是基于[PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN)实现的视频唇形同步模型**Wav2lip**, 它实现了人物口型与输入语音同步，俗称「对口型」。 比如这样：



```
<iframe  width="1200" height="800" src="//player.bilibili.com/player.html?aid=848895487&bvid=BV1wL4y1q7Mb&cid=435817783&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
```



**不仅仅让静态图像会「说话」，Wav2lip还可以直接将动态的视频，进行唇形转换，输出与目标语音相匹配的视频，自制视频配音不是梦！**



**若是大家喜欢这个教程，欢迎到[Github PaddleGAN主页](https://github.com/PaddlePaddle/PaddleGAN)点击star呀！下面就让我们一起动手实现吧！**
<div align='left'>
  <img src='https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f7ce273ee34a4217bd6d959dafa050da~tplv-k3u1fbpfcp-zoom-1.image' width='1000'/>
</div>



## 2.Wav2lip模型原理
Wav2lip实现唇形与语音精准同步突破的关键在于，它采用了**唇形同步判别器，以强制生成器持续产生准确而逼真的唇部运动。**

此外，该研究通过在鉴别器中，使用**多个连续帧而不是单个帧，并使用视觉质量损失（而不仅仅是对比损失）来考虑时间相关性，从而改善了视觉质量。**

该wav2lip模型几乎是**万能**的，适用于任何**人脸**、**任何语音**、**任何语言**，对任意视频都能达到很高的准确率，可以无缝地与原始视频融合，还可以用于**转换动画人脸，并且导入合成语音**也是可行的

# 二、环境准备

## 1.下载PaddleGAN代码


```python
# 从github上克隆PaddleGAN代码（如下载速度过慢，可用gitee源）
!git clone https://gitee.com/PaddlePaddle/PaddleGAN
#!git clone https://github.com/PaddlePaddle/PaddleGAN
```

    Cloning into 'PaddleGAN'...
    remote: Enumerating objects: 565, done.[K
    remote: Counting objects: 100% (565/565), done.[K
    remote: Compressing objects: 100% (315/315), done.[K
    remote: Total 3944 (delta 326), reused 459 (delta 235), pack-reused 3379[K
    Receiving objects: 100% (3944/3944), 161.95 MiB | 25.73 MiB/s, done.
    Resolving deltas: 100% (2534/2534), done.
    Checking connectivity... done.


## 2.安装sndfile、libsndfile


```python
# 安装所需安装包
!mkdir sndfile
%cd ~/sndfile
!wget http://www.mega-nerd.com/libsndfile/files/libsndfile-1.0.28.tar.gz
!tar xzvf libsndfile-1.0.28.tar.gz

%cd libsndfile-1.0.28
!./configure --prefix=/home/aistudio/build_libs CFLAGS=-fPIC --enable-shared 
!make
!make install
```

## 3.安装PaddleGAN


```python
%cd ~/PaddleGAN
!pip install -r requirements.txt
!pip install -e .
%cd applications/
```

# 三、数据准备

## 1.声音准备
选取抖音里得视频，通过ffmp提取声音

```
 !ffmpeg -i 1.mp4 -f s16le -ar 16000 1.wav
```




```python
%cd ~
!ffmpeg -i  1.mp4 -vn -codec copy 1.m4a
```

    /home/aistudio
    ffmpeg version 2.8.15-0ubuntu0.16.04.1 Copyright (c) 2000-2018 the FFmpeg developers
      built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.10) 20160609
      configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv
      libavutil      54. 31.100 / 54. 31.100
      libavcodec     56. 60.100 / 56. 60.100
      libavformat    56. 40.101 / 56. 40.101
      libavdevice    56.  4.100 / 56.  4.100
      libavfilter     5. 40.101 /  5. 40.101
      libavresample   2.  1.  0 /  2.  1.  0
      libswscale      3.  1.101 /  3.  1.101
      libswresample   1.  2.101 /  1.  2.101
      libpostproc    53.  3.100 / 53.  3.100
    Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '1.mp4':
      Metadata:
        major_brand     : isom
        minor_version   : 512
        compatible_brands: isomiso2avc1mp41
        encoder         : Lavf58.12.100
      Duration: 00:00:06.63, start: 0.000000, bitrate: 1437 kb/s
        Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, smpte170m/bt470bg/smpte170m), 720x1280 [SAR 1:1 DAR 9:16], 1300 kb/s, 29.85 fps, 30 tbr, 10000k tbn, 60 tbc (default)
        Metadata:
          handler_name    : VideoHandler
        Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)
        Metadata:
          handler_name    : SoundHandler
    [1;35m[ipod @ 0xa63720] [0m[0;33mCodec for stream 0 does not use global headers but container format requires global headers
    [0mOutput #0, ipod, to '1.m4a':
      Metadata:
        major_brand     : isom
        minor_version   : 512
        compatible_brands: isomiso2avc1mp41
        encoder         : Lavf56.40.101
        Stream #0:0(und): Audio: aac (mp4a / 0x6134706D), 44100 Hz, stereo, 128 kb/s (default)
        Metadata:
          handler_name    : SoundHandler
    Stream mapping:
      Stream #0:1 -> #0:0 (copy)
    Press [q] to stop, [?] for help
    size=     104kB time=00:00:06.54 bitrate= 130.3kbits/s    
    video:0kB audio:102kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.781061%


## 2.图片或视频
随机网上百度卡通美女照片一张


```python
from PIL import Image
img=Image.open('1.jpg')
img
```





![360截图20220803191040035.jpg](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7e5f5893a1544dfabd6094b1a25b12fa~tplv-k3u1fbpfcp-watermark.image?)



# 四、使用模型进行合成
## 1.唇形动作合成命令使用说明

重点来啦！！本项目支持大家上传自己准备的视频和音频， 合成任意想要的**逼真的配音视频**！！![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0ac3a25d89442f880b5c34c58d075e2~tplv-k3u1fbpfcp-zoom-1.image)



只需在如下命令中的**face参数**和**audio参数**分别换成自己的视频和音频路径，然后运行如下命令，就可以生成和音频同步的视频。

程序运行完成后，会在当前文件夹下生成文件名为**outfile**参数指定的视频文件，该文件即为和音频同步的视频文件。本项目中提供了demo展示所用到的视频和音频文件。具体的参数使用说明如下：
- face: 原始视频，视频中的人物的唇形将根据音频进行唇形合成--通俗来说，想让谁说话
- audio：驱动唇形合成的音频，视频中的人物将根据此音频进行唇形合成--通俗来说，想让这个人说什么

## 2.numba降级

numba报错，需要对numba进行降级,但是requirements.txt里为 **numba==0.53.1**
```
 File "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/librosa/util/utils.py", line 15, in <module>
    from .decorators import deprecated
  File "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/librosa/util/decorators.py", line 9, in <module>
    from numba.decorators import jit as optional_jit
ModuleNotFoundError: No module named 'numba.decorators'
```


```python
!pip uninstall numba -y
!pip install numba==0.48.0 --user
```

提示
```
ERROR: ppgan 2.0.0 has requirement numba==0.53.1, but you'll have numba 0.48.0 which is incompatible.
Installing collected packages: numba
Successfully installed numba-0.48.0
```
但是默认高版本就报 `ModuleNotFoundError: No module named 'numba.decorators'`


```python
!pip list|grep numba
```

## 3.视频合成


```python
%cd /home/aistudio/PaddleGAN/applications/
!export PYTHONPATH=$PYTHONPATH:/home/aistudio/work/PaddleGAN && python tools/wav2lip.py --face /home/aistudio/1.jpg --audio /home/aistudio/1.m4a --outfile /home/aistudio/bb.mp4
```

## 4.成果展示

**视频比较长的话，运行时间会稍长，建议把视频下载到本地预览**


<iframe  width="800" height="600" src="//player.bilibili.com/player.html?aid=848895487&bvid=BV1wL4y1q7Mb&cid=435817783&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>


# 五、总结
**首先帮大家总结一波：让图片会说话、视频花式配音的魔法--Wav2lip的使用只用三步**：
1. 环境准备：安装Paddle环境并下载[PaddleGAN](https://github.com/PaddlePaddle/PaddleGAN)
2. 素材准备：选择（抓取或录制）想要「配音/对口型」的对象以及音频内容
3. 运行代码：运行代码并保存制作完成的对口型视频分享惊艳众人

