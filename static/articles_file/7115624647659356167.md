<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4fb0cd364aed43a79586664595267bbe~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

> [ShowMeAI](<http://www.showmeai.tech/>)**日报**系列全新升级！覆盖AI人工智能 工具&框架 | 项目&代码 | 博文&分享 | 数据&资源 | 研究&论文 等方向。点击查看 [**历史文章列表**](https://mp.weixin.qq.com/mp/homepage?__biz=Mzg2OTYyMTcwMw==&hid=2&sn=51f7bead52c41447cd0ecb3d57b884e7)，在公众号内订阅话题 **#ShowMeAI资讯日报**，可接收每日最新推送。点击 [**专题合辑&电子月刊**](http://www.showmeai.tech/tutorials/85) 快速浏览各专题全集。


# 工具&框架

## 🚧『HyperState』用于管理机器学习训练系统超参数配置和可变程序状态的库


[https://github.com/cswinter/hyperstate](https://github.com/cswinter/hyperstate)


<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/937ed7efc5084383a13a0314edc793c6~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## 🚧『Knowhere』集成了FAISS，HNSW和Annoy的开源向量搜索引擎


[https://github.com/milvus-io/knowhere](https://github.com/milvus-io/knowhere)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/287f9924b0db440bb4a597964dff0458~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## 🚧『Wis3D』面向3D计算机视觉的Web版3D可视化工具

[https://github.com/zju3dv/Wis3D](https://github.com/zju3dv/Wis3D)


<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3bd66d40086942979d150940559593bd~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0a6d4b505c2d477c9c3399126c90b40b~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/84a7439eb0894a688a922f0cc126d75b~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## 🚧『paperlib』面向计算机科学的简单开源学术论文管理工具

[https://github.com/GeoffreyChen777/paperlib](https://github.com/GeoffreyChen777/paperlib)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ecf01cf1400c4e0f99429670e09e1d0a~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## 🚧『tract』支持Tensorflow 1, ONNX or NNEF的神经网络推理工具包

[https://github.com/sonos/tract](https://github.com/sonos/tract)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/37d5f539b6124c21b1d34924bf327b4e~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

# 项目&代码
## 👍『min(DALL·E)』DALL·E Mini的最小化实现，基于文字提示做图创作

[https://github.com/kuprel/min-dalle](https://github.com/kuprel/min-dalle)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/060ac40fe4e04e699362230a20304b1d~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

# 博文&分享

## 📚『十分钟入门MLOps』博文 MLOps in 10 Minutes

[https://towardsdatascience.com/mlops-in-10-minutes-165c746a9b8e](https://towardsdatascience.com/mlops-in-10-minutes-165c746a9b8e)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9819219e97546c09f2a3bfd1834f294~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## 📚『程序员应该知道的97件事』免费书

[http://97-things-every-x-should-know.gitbook.io/97-things-every-programmer-should-know/en](http://97-things-every-x-should-know.gitbook.io/97-things-every-programmer-should-know/en)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4748f13e36645b19758b943eff7ecbd~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>


# 数据&资源

## 🔥『HM3D-ABO Dataset』照片级以对象为中心的多视图数据集

[https://github.com/zhenpeiyang/HM3D-ABO](https://github.com/zhenpeiyang/HM3D-ABO)

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/35a8bb4ff8414bc5a12504c48b5daab3~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>


# 研究&论文

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bd41fe32e4b044a5aef6a83eef0b7ecf~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>


> 公众号回复关键字 **日报**，免费获取整理好的论文合辑。


## ⚡ 论文：Pen and Paper Exercises in Machine Learning

**论文标题**：Pen and Paper Exercises in Machine Learning

**论文时间**：27 Jun 2022

**所属领域**：**机器学习**

**对应任务**：Variational Inference，变分推理

**论文地址**：[https://arxiv.org/abs/2206.13446](https://arxiv.org/abs/2206.13446)

**代码实现**：[https://github.com/michaelgutmann/ml-pen-and-paper-exercises](https://github.com/michaelgutmann/ml-pen-and-paper-exercises)

**论文作者**：Michael U. Gutmann

**论文简介**：This is a collection of (mostly) pen-and-paper exercises in machine learning./这是一组机器学习中的纸笔练习（推导）。

> **论文摘要**：这是一组机器学习方面的纸笔练习。这些练习涉及以下主题：线性代数、优化、有向图形模型、无向图形模型、图形模型的表达能力、因子图和消息传递、隐马尔科夫模型的推理、基于模型的学习（包括ICA和非归一化模型）、采样和蒙特卡洛集成以及变分推理。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/af66bd385c404845bce9decba431f5ce~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/171713803616482086c26ac2d02175ef~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：HM3D-ABO: A Photo-realistic Dataset for Object-centric Multi-view 3D Reconstruction

**论文标题**：HM3D-ABO: A Photo-realistic Dataset for Object-centric Multi-view 3D Reconstruction

**论文时间**：24 Jun 2022

**所属领域**：计算机视觉

**对应任务**：3D Reconstruction，Novel View Synthesis，Pose Estimation，三维重建，新视点合成，姿势估计

**论文地址**：[https://arxiv.org/abs/2206.12356](https://arxiv.org/abs/2206.12356)

**代码实现**：[https://github.com/zhenpeiyang/hm3d-abo](https://github.com/zhenpeiyang/hm3d-abo)

**论文作者**：Zhenpei Yang, Zaiwei Zhang, QiXing Huang

**论文简介**：Reconstructing 3D objects is an important computer vision task that has wide application in AR/VR./重构3D物体是一项重要的计算机视觉任务，在AR/VR中有着广泛的应用。


> **论文摘要**：重构3D物体是一项重要的计算机视觉任务，在AR/VR中有着广泛的应用。为这项任务开发的深度学习算法通常依赖于一个非真实的合成数据集，如ShapeNet和Things3D。另一方面，现有的以真实拍摄的物体为中心的数据集通常没有足够的注释来实现监督训练或可靠的评估。在这份技术报告中，我们提出了一个以照片为中心的物体数据集HM3D-ABO。它是由现实的室内场景和现实的物体组成的。对于每个配置，我们都提供了多视角的RGB观测数据、物体的水密网状模型、地面真实深度图和物体掩码。这份数据集也可用于相机姿势估计和新视角合成等任务。数据集的生成代码已在 [https://github.com/zhenpeiyang/HM3D-ABO]()

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7b49d59ea5bc4196867bacccf1a6eb12~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/608a56292459478199b7aa4c8cc05a6b~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：Latent Image Animator: Learning to animate image via latent space navigation

**论文标题**：Latent Image Animator: Learning to animate image via latent space navigation

**论文时间**：ICLR 2022

**所属领域**：计算机视觉

**对应任务**：Image Animation，Video Generation，图像动画，视频生成

**论文地址**：[https://arxiv.org/abs/2203.09043](https://arxiv.org/abs/2203.09043)

**代码实现**：[https://github.com/wyhsirius/LIA](https://github.com/wyhsirius/LIA)

**论文作者**：Yaohui Wang, Di Yang, Francois Bremond, Antitza Dantcheva

**论文简介**：Deviating from such models, we here introduce Latent Image Animator (LIA), a self-supervised auto-encoder that evades need for structure representation./与这些模型不同的是，我们在此介绍了Latent Image Animator (LIA)，它是一种自监督的自动编码器，不需要结构表示。

> **论文摘要**：由于生成对抗网络（GANs）和自动编码器的显著进步，图像动画变得越来越逼真，也越来越高效。目前的动画方法通常利用从驾驶视频中提取的结构表示。这种结构表示（如关键点或区域）有助于将运动从驾驶视频转移到静态图像。然而，这种方法在源图像和驾驶视频包含大量外观变化的情况下是失败的。此外，结构信息的提取需要额外的模块，从而使动画模型的复杂性增加。与这些模型不同的是，我们在此介绍了Latent Image Animator（LIA），这是一个自监督的自动编码器，避免了对结构表示的需要。LIA是通过在潜伏空间中的线性导航来精简图像的动画。具体来说，生成的视频中的运动是通过潜空间中代码的线性位移来构建的。为此，我们同时学习一组正交的运动方向，并使用它们的线性组合来表示潜空间中的任何位移。广泛的定量和定性分析表明，我们的模型在VoxCeleb、Taichi和TED-talk数据集上的生成质量方面系统地、明显地超过了最先进的方法。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/963bda2ee4f648fe8598f54a64d3e4dd~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d86d8182d3fa45608f3ca375aaba31b6~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：GhostNets on Heterogeneous Devices via Cheap Operations

**论文标题**：GhostNets on Heterogeneous Devices via Cheap Operations

**论文时间**：10 Jan 2022

**所属领域**：计算机视觉

**论文地址**：[https://arxiv.org/abs/2201.03297](https://arxiv.org/abs/2201.03297)

**代码实现**：[https://github.com/huawei-noah/CV-backbones](https://github.com/huawei-noah/CV-backbones) , [https://github.com/LKLQQ/ghostnet_d](https://github.com/LKLQQ/ghostnet_d)

**论文作者**：Kai Han, Yunhe Wang, Chang Xu, Jianyuan Guo, Chunjing Xu, Enhua Wu, Qi Tian

**论文简介**：The proposed C-Ghost module can be taken as a plug-and-play component to upgrade existing convolutional neural networks./提出的C-Ghost模块可以作为一个即插即用的组件来升级现有的卷积神经网络。

> **论文摘要**：由于内存和计算资源有限，在移动设备上部署卷积神经网络（CNN）是困难的。我们旨在通过利用特征图中的冗余，为包括CPU和GPU在内的异构设备设计高效的神经网络，这在神经架构设计中很少被研究。对于类似CPU的设备，我们提出了一个新颖的CPU高效的Ghost（C-Ghost）模块，从廉价的操作中产生更多的特征图。基于一组内在特征图，我们应用一系列成本低廉的线性变换来生成许多ghost特征图，这些特征图可以充分揭示内在特征的基础信息。提出的C-Ghost模块可以作为一个即插即用的组件来升级现有的卷积神经网络。C-Ghost瓶颈被设计为堆叠C-Ghost模块，然后轻量级的C-GhostNet就可以轻松建立。我们进一步考虑GPU设备的高效网络。在不涉及过多的GPU低效操作（例如，深度卷积）的情况下，我们建议利用阶段性特征冗余来制定GPU高效的Ghost（G-Ghost）阶段结构。阶段中的特征被分成两部分，第一部分使用输出通道较少的原始块进行处理以生成固有特征，另一部分则通过利用阶段性的冗余来生成廉价的操作。在基准上进行的实验证明了拟议的C-Ghost模块和G-Ghost阶段的有效性。C-GhostNet和G-GhostNet可以分别在CPU和GPU上实现精度和延迟的最佳权衡。代码可在 [https://github.com/huawei-noah/CV-backbones](https://github.com/huawei-noah/CV-backbones) 查看。
 
<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4c2709a4493044bc9327debf26bca285~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/24f2bfbd5a874f0e90ab09e004e2e5fb~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：BackdoorBench: A Comprehensive Benchmark of Backdoor Learning

**论文标题**：BackdoorBench: A Comprehensive Benchmark of Backdoor Learning

**论文时间**：25 Jun 2022

**所属领域**：对抗网络

**对应任务**：Backdoor Attack，攻击对抗

**论文地址**：[https://arxiv.org/abs/2206.12654](https://arxiv.org/abs/2206.12654)

**代码实现**：[https://github.com/sclbd/backdoorbench](https://github.com/sclbd/backdoorbench)

**论文作者**：Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen, Hongyuan Zha

**论文简介**：However, we find that the evaluations of new methods are often unthorough to verify their claims and real performance, mainly due to the rapid development, diverse settings, as well as the difficulties of implementation and reproducibility./然而，我们发现，对新方法的评估往往是不彻底的，无法验证其主张和实际性能，这主要是由于发展迅速，设置多样，以及实施和可重复性困难。

> **论文摘要**：Backdoor学习是研究深度神经网络（DNNs）脆弱性的一个新兴的重要课题。许多开创性的Backdoor攻击和防御方法被陆续或同时提出，处于快速军备竞赛的状态。然而，我们发现，对新方法的评估往往是不彻底的，无法验证其主张和实际性能，这主要是由于发展迅速、环境多样以及实施和可重复性困难。如果没有彻底的评估和比较，就很难跟踪当前的进展和设计文献的未来发展路线图。为了缓解这一困境，我们建立了一个全面的Backdoor学习基准，称为BackdoorBench。它包括一个可扩展的基于模块化的代码库（目前包括8种最先进的（SOTA）攻击和9种SOTA防御算法的实现），以及一个完整的后门学习的标准化协议。我们还提供了基于5个模型和4个数据集的每一对8种攻击与9种防御的综合评估，其中有5种中招概率，因此总共有8000对评估。我们进一步从不同角度对这8,000个评价进行分析，研究攻击对防御算法、中招率、模型和数据集在后门学习中的影响。BackdoorBench的所有代码和评估均可在 [https://backdoorbench.github.io](https://backdoorbench.github.io) 上公开获得。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2364af48a5704b26b6d4b9ac7d944f61~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b647ba9615274b8cad722743ec6af939~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：Controlling strokes in fast neural style transfer using content transforms
 
**论文标题**：Controlling strokes in fast neural style transfer using content transforms
**论文时间**：The Visual Computer 2022
**所属领域**：计算机视觉
**对应任务**：Style Transfer，风格迁移
**论文地址**：[https://link.springer.com/article/10.1007/s00371-022-02518-x#Fn1](https://link.springer.com/article/10.1007/s00371-022-02518-x#Fn1)
**代码实现**：[https://github.com/MaxReimann/stroke-adjustable-nst-transforms](https://github.com/MaxReimann/stroke-adjustable-nst-transforms)
**论文作者**：Max Reimann, Benito Buchheim, Amir Semmo, Jürgen Döllner, Matthias Trapp

**论文简介**：To demonstrate the real-world applicability of our approach, we present StyleTune, a mobile app for interactive editing of neural style transfers at multiple levels of control./为了证明我们的方法在现实世界中的适用性，我们提出了StyleTune，一个在多个控制层次上对神经风格转移进行交互式编辑的移动应用程序。

> **论文摘要**：快速风格转移方法最近在艺术相关的应用中得到了欢迎，因为它们使图像的通用实时风格化成为可能。然而，它们大多局限于有关风格元素互动调整的一次性风格化。特别是，对笔画大小或笔画方向的表达性控制仍然是一个公开的挑战。为此，我们提出了一种新型的可调整笔画的快速风格转换网络，它能够同时控制笔画的大小和强度，并通过利用卷积神经网络的标度变异，使编辑的表现力比目前的方法更广泛。此外，我们为风格元素的编辑引入了一种与网络无关的方法，通过应用可逆的输入转换，可以调整风格化输出中的笔画。在这一点上，笔画的方向可以被调整，基于扭曲的效果可以被应用于风格元素，如漩涡或波浪。为了证明我们的方法在现实世界中的适用性，我们提出了StyleTune，一个在多个控制层次上对神经风格转移进行交互式编辑的移动应用程序。我们的应用程序允许在全局和局部层面进行笔画调整。此外，它还实现了一个基于设备补丁的升采样步骤，使用户能够实现具有高输出保真度和超过2000万像素分辨率的结果。我们的方法允许用户对他们的创作进行艺术指导，并实现目前的风格转移应用程序所不能实现的结果。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ce614f9981f345929fd984d503035de1~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/57e52f8351d7447d914b36047e00d246~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6f3ff0bdc7844323ad9791b313169b4b~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>



## ⚡ 论文：BokehMe: When Neural Rendering Meets Classical Rendering

**论文标题**：BokehMe: When Neural Rendering Meets Classical Rendering
**论文时间**：CVPR 2022
**所属领域**：计算机视觉
**对应任务**：Neural Rendering，神经渲染
**论文地址**：[https://arxiv.org/abs/2206.12614](https://arxiv.org/abs/2206.12614)
**代码实现**：[https://github.com/juewenpeng/bokehme](https://github.com/juewenpeng/bokehme)
**论文作者**：Juewen Peng, Zhiguo Cao, Xianrui Luo, Hao Lu, Ke Xian, Jianming Zhang
**论文简介**：Based on this formulation, we implement the classical renderer by a scattering-based method and propose a two-stage neural renderer to fix the erroneous areas from the classical renderer./基于这种表述，我们通过一种基于散射的方法来实现经典的渲染器，并提出一种两阶段的神经渲染器来修复经典渲染器中的错误区域。

> **论文摘要**：我们提出了BokehMe，一个混合的虚化渲染框架，它将神经渲染器与经典的物理动机渲染器结合起来。给定一张图片和一个可能不完美的差异图，BokehMe生成高分辨率的照片般真实的虚化效果，其模糊大小、焦平面和光圈形状均可调整。为此，我们分析了基于散射的经典方法的误差，并得出了计算误差图的公式。基于这个公式，我们用基于散射的方法实现了经典的渲染器，并提出了一个两阶段的神经渲染器来修复经典渲染器中的错误区域。神经渲染器采用了动态多尺度方案来有效地处理任意的模糊尺寸，并对其进行训练以处理不完美的差异输入。实验表明，我们的方法在合成图像数据和具有预测差异的真实图像数据上与以前的方法相比都有优势。我们进一步进行了用户研究，以验证我们方法的优势。

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/49a2672b37534c0d957231c6d822b741~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/03e37ae764ee414fbfd84b3b06caa9ce~tplv-k3u1fbpfcp-zoom-1.image" width="70%" referrerpolicy="no-referrer"></div>

## ⚡ 论文：Pixel-wise Energy-biased Abstention Learning for Anomaly Segmentation on Complex Urban Driving Scenes

**论文标题**：Pixel-wise Energy-biased Abstention Learning for Anomaly Segmentation on Complex Urban Driving Scenes

**论文时间**：24 Nov 2021

**所属领域**：无人驾驶

**对应任务**：Anomaly Detection，Semantic Segmentation，异常检测，语义分割

**论文地址**：[https://arxiv.org/abs/2111.12264](https://arxiv.org/abs/2111.12264)

**代码实现**：[https://github.com/tianyu0207/pebal](https://github.com/tianyu0207/pebal)

**论文作者**：Yu Tian, Yuyuan Liu, Guansong Pang, Fengbei Liu, Yuanhong Chen, Gustavo Carneiro

**论文简介**：However, previous uncertainty approaches that directly associate high uncertainty to anomaly may sometimes lead to incorrect anomaly predictions, and external reconstruction models tend to be too inefficient for real-time self-driving embedded systems./然而，以前直接将高不确定性与异常情况联系起来的不确定性方法有时可能会导致不正确的异常预测，而且外部重建模型对于实时自动驾驶的嵌入式系统来说往往效率太低。


> **论文摘要**：在复杂的城市驾驶场景中，最先进的（SOTA）异常分割方法探索了从离群暴露或外部重建模型中学到的像素级分类不确定性。然而，以前的不确定性方法直接将高不确定性与异常情况联系起来，有时可能会导致不正确的异常预测，而且外部重建模型对于实时自动驾驶嵌入式系统来说往往效率太低。在本文中，我们提出了一种新的异常分割方法，命名为像素级能量偏向的弃权学习（PEBAL），它用一个学习自适应像素级异常类别的模型和一个学习离群像素分布的基于能量的模型（EBM）来探索像素级弃权学习（AL）。更具体地说，PEBAL是基于EBM和AL的非微妙的联合训练，其中EBM被训练成输出高能量的异常像素（来自异常点的暴露），AL被训练成使这些高能量像素在被纳入异常类时得到适应性的低惩罚。我们针对SOTA对PEBAL进行了广泛的评估，并表明它在四个基准中取得了最佳性能。代码可在 [https://github.com/tianyu0207/pebal](https://github.com/tianyu0207/pebal) 获取


> 我们是 [**ShowMeAI**](http://www.showmeai.tech/tutorials/85)，致力于传播AI优质内容，分享行业解决方案，用知识加速每一次技术成长！点击查看 [**历史文章列表**](https://mp.weixin.qq.com/mp/homepage?__biz=Mzg2OTYyMTcwMw==&hid=2&sn=51f7bead52c41447cd0ecb3d57b884e7)，在公众号内订阅话题 **#ShowMeAI资讯日报**，可接收每日最新推送。点击 [**专题合辑&电子月刊**](http://www.showmeai.tech/tutorials/85) 快速浏览各专题全集。


<div align=center><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6fdca823abe949a39d89d085d6bb9501~tplv-k3u1fbpfcp-zoom-1.image" width="100%" referrerpolicy="no-referrer"></div>

- 作者：[韩信子](https://github.com/HanXinzi-AI)@[ShowMeAI](http://www.showmeai.tech/tutorials/85)
- [**历史文章列表**](https://mp.weixin.qq.com/mp/homepage?__biz=Mzg2OTYyMTcwMw==&hid=2&sn=51f7bead52c41447cd0ecb3d57b884e7)
- [**专题合辑&电子月刊**](http://www.showmeai.tech/tutorials/85) 
- **声明：版权所有，转载请联系平台与作者并注明出处**
- **欢迎回复，拜托点赞，留言推荐中有价值的文章、工具或建议，我们都会尽快回复哒~**
