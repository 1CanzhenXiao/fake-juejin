---
theme: channing-cyan
highlight: agate
---
携手创作，共同成长！这是我参与「掘金日新计划 · 8 月更文挑战」的第4天，[点击查看活动详情](https://juejin.cn/post/7123120819437322247 "https://juejin.cn/post/7123120819437322247") >>

# 前言
今天的主要目的还是快速上手目标跟踪，先前的话我是简单说了一下卡尔曼滤波，然后由于博客的问题，没有说完。本来是想做一个系列的，但是很难整理，而且说实话有些东西我也没搞清楚。当然这并不影响我们使用，抽象一下继续happy，就像你不懂SpringBoot 或者Django底层一样，还是阔以做出一个网站的。
# 算法简介
首先我们这边的话其实整个项目呢，是两个部分，一个是目标的追踪部分，还有一个是目标的识别检测部分。我们要先检测出来一个物品，我们才能去跟踪，同时这个算法也是基于目标检测算法来的。

他们之间的关系就是这样的：

![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eb3f2d65bada4b49ad1161b3b8cc3a3f~tplv-k3u1fbpfcp-zoom-1.image)
那么目标检测的话这里就不多说了。

可以参考这几篇博文：

[GitHub 水项目之 快速上手 YOLOV5](https://blog.csdn.net/FUTEROX/article/details/124079281?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165919148316782425192159%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=165919148316782425192159&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-5-124079281-null-null.nonecase&utm_term=Yolo&spm=1018.2226.3001.4450)

[YOLOV5 参数设定与模型训练的坑点一二三](https://blog.csdn.net/FUTEROX/article/details/124079281?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165919148316782425192159%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=165919148316782425192159&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-5-124079281-null-null.nonecase&utm_term=Yolo&spm=1018.2226.3001.4450)

[YOLOV1论文小整理](https://blog.csdn.net/FUTEROX/article/details/124111506?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165932334416781683983318%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=165932334416781683983318&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-124111506-null-null.nonecase&utm_term=yolov1&spm=1018.2226.3001.4450)
以及这篇博文：
[手把手教你如何自制目标检测框架（从理论到实现）](https://blog.csdn.net/FUTEROX/article/details/126076046?spm=1001.2014.3001.5501)


所以我们这边主要就是咱们deepsort的一个情况。


# sort算法
说到这个玩意就还得得先说说sort算法。

前面在说到目表跟踪的时候，我们说到了[卡尔曼滤波](https://blog.csdn.net/FUTEROX/article/details/126154459?spm=1001.2014.3001.5501)
但是这个只是解决了一个问题，就是我们预测改物体下一个框可能存在的位置，之后我们计算一些IOU确定一下这个下一个框确定是我们的目标物体的，从而确定他的轨迹完成目标跟踪。

但是我们先前假设的是单目标的一个情况，如果是多目标的话，还涉及到如何去分配一个跟踪的目标的问题。也就是给目标不同的标号，然后识别预测到他的轨迹之后，确定这个轨迹是哪个目标的。


所以这个sort算法其实有两个部分，也就是为了完成我们的一个目标跟踪。

一个是匈牙利算法，目的是为了确定谁是谁，一个是卡尔曼为了预测出物体的一个状态进行跟踪。


![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4f47ecf5755a4546800632ef5328f492~tplv-k3u1fbpfcp-zoom-1.image)

# deepsort
deepsort 是在sort算法基础上做了很多别的工作。

> 由于sort算法还是比较粗糙的追踪算法，当物体发生遮挡的时候，特别容易丢失自己的ID。而Deepsort算法在sort算法的基础上增加了级联匹配(MatchingCascade)和新轨迹的确认(confirmed)。Tracks分为确认态(confirmed),和不确认态(unconfirmed),新产生的Tracks是不确认态的：不确认态的Tracks必须要和Detections连续匹配一定的次数（默认是3)才可以转化成确认态。确认态的Tracks必须和Detectionsi连续失配一定次数（默认30次），才会被删除。


那么他的算法流程大概是这样的:
(知乎大佬的图）
![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/509f9bbfd7fc463c995448b26a13d513~tplv-k3u1fbpfcp-zoom-1.image)



# 项目结构

我们今天这里的话，还是先简单的去做一个介绍，之后的话咱们到像以前yolo一样如何训练自己的模型，然后完成自己的一个需求。

![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a1423b1229c94b1cbe38566d361e905a~tplv-k3u1fbpfcp-zoom-1.image)


我们重点先看到这个deep_sort
![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/36d6a3aaded14929bc21dd3867dc2dc7~tplv-k3u1fbpfcp-zoom-1.image)
这里我先对这些参数进行一个说明。

> （1）里面有特征提取权重的目录路径；
> 
> （2）最大余弦距离，用于级联匹配，如果大于该阈值，则忽略。
> 
> （3）检测结果置信度阈值
> 
> （4）非极大抑制阈值，设置为1代表不进行抑制
> 
> （5）最大IOU阈值
> 
> （6）最大寿命，也就是经过MAX_AGE帧没有追踪到该物体，就将该轨迹变为删除态。
> 
> （7）最高击中次数，如果击中该次数，就由不确定态转为确定态。
> 
> （8）最大保存特征帧数，如果超过该帧数，将进行滚动保存。


那么之后的话我们打开deepsort文件夹，可以看到这些玩意：

![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/80c7e3b2345d4fa7a1ca39446dc3c2d1~tplv-k3u1fbpfcp-zoom-1.image)
里面还是有sort算法的。

> ckpt.t7：这是一个特征提取网络的权重文件，特征提取网络训练好了以后会生成这个权重文件，方便在目标追踪的时候提取目标框中的特征，在目标追踪的时候避免ID交换。 
> 
> evaluate.py：计算特征提取模型精确度。
> 
> feature_extractor.py：提取对应boundingbox中的特征, 得到一个固定维度的特征，作为该bounding box的代表，供计算相似度时使用。
> 
> model.py：特征提取网络模型，该模型用来提取训练特征提取网络权重。 train.py：训练特征提取网络的python文件
> 
> test.py：测试训练好的特征提取网络的性能


那么此外sort算法对应的是这个玩意
![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e45a32881f5c40329523d773682b6d7a~tplv-k3u1fbpfcp-zoom-1.image)
detection.py：保存通过目标检测的一个检测框框，以及该框的置信度和获取的特征；同时还提供了框框的各种格式的转化方法。

> iou_matching.py：计算两个框框之间的IOU。
> 
> kalman_filter.py：卡尔曼滤波器的相关代码，主要是利用卡尔曼滤波来预测检测框的轨迹信息。
> 
> linear_assignment.py：利用匈牙利算法匹配预测的轨迹框和检测框最佳匹配效果。
> 
> nn_matching.py：通过计算欧氏距离、余弦距离等距离来计算最近领距离。
> 
> preprocessing.py：非极大抑制代码，利用非极大抑制算法将最优的检测框输出。
> 
> track.py：主要储存的是轨迹信息，其中包括轨迹框的位置和速度信息，轨迹框的ID和状态，其中状态包括三种，一种是确定态、不确定态、删除态三种状态。
> 
> tracker.py：保存了所有的轨迹信息，负责初始化第一帧，卡尔曼滤波的预测和更新，负责级联匹配,IOU匹配。
> 


那么回到我们的根目录：
![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/483e1f20fb464415a8d2393a5bf123ec~tplv-k3u1fbpfcp-zoom-1.image)

> deep_sort/deep_sort/deep_sort.py：deepsort的整体封装，实现一个deepsort追踪的一个整体效果。
> 
> deep_sort/utils：这里最主要有一些各种各样的工具python代码，例如画框工具，日志保存工具等等。
> 
> fuck.py：针对读取的视频进行目标追踪
> 
> objdetector.py：封装的一个目标检测器，对视频中的物体进行检测
> 
> objtracker.py：封装了一个目标追踪器，对检测的物体进行追踪


最后来看看效果演示
![请添加图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0aed043ebbc4f80815783dcdf4a507e~tplv-k3u1fbpfcp-zoom-1.image)
